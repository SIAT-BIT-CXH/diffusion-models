




























































  0% 102/50000 [02:04<16:51:28,  1.22s/it]
Traceback (most recent call last):
  File "train_ddpm_cont.py", line 11, in <module>
    diffusion.train()
  File "/content/drive/My Drive/Colab Notebooks/ddpm_hw_clean/diffusion.py", line 196, in train
    self.optimizer_step(loss)
  File "/content/drive/My Drive/Colab Notebooks/ddpm_hw_clean/diffusion.py", line 154, in optimizer_step
    self.optimizer.step()
  File "/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py", line 88, in wrapper
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py", line 28, in decorate_context
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py", line 144, in step
    eps=group['eps'])
  File "/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py", line 94, in adam
    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)
KeyboardInterrupt